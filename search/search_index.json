{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"\u7b14\u8bb0\u672c\u7b80\u4ecb \u00b6 \u8be5\u9875\u4e0b\u4e3b\u8981\u8bb0\u5f55Yang\u8bb0\u5f55\u7684\u7b14\u8bb0","title":"\u603b\u8ff0"},{"location":"#_1","text":"\u8be5\u9875\u4e0b\u4e3b\u8981\u8bb0\u5f55Yang\u8bb0\u5f55\u7684\u7b14\u8bb0","title":"\u7b14\u8bb0\u672c\u7b80\u4ecb"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/0/","text":"\u603b\u8ff0 \u00b6 \u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u673a\u5668\u4eba\u6293\u53d6\uff0c\u76ee\u524d(20190803 21:50)\u770b\u4e86USA\u4e1c\u5317\u5927\u5b66Helping Hands\u5b9e\u9a8c\u5ba4\u7684 \u8bba\u6587 \u505a\u7684\u7a0d\u597d\u4e00\u4e9b\uff0c\u5b9e\u9a8c\u5ba4\u7684\u5de5\u4f5c\u6709\u5ef6\u7eed\u6027\uff0c\u4ee3\u7801\u516c\u5f00\uff08\u505a\u6210\u4e86ROS\u529f\u80fd\u5305\uff09\u3002\u8fd1\u4e24\u5e74\u7684\u8bba\u6587\u5b9e\u9a8c\u7ed3\u679c\u770b\u8d77\u6765\u8fd8\u4e0d\u9519\u3002\u4f46\u662f\u8fd9\u4e2a\u5b9e\u9a8c\u5ba4\u5199\u7684\u8bba\u6587\u5f88\u559c\u6b22\u7528\u6570\u5b66\u7b26\u53f7\u5b9a\u4e49\u4e00\u4e9b\u6982\u5ff5\uff0c\u5bfc\u81f4\u6574\u7bc7\u8bba\u6587\u770b\u4e0a\u53bb\u5168\u90e8\u662f\u516c\u5f0f\uff0c\u8ba9\u6211\u770b\u5f97\u8111\u58f3\u75bc\u3002 \u8bba\u6587 Deep Learning for Detecting Robotic Grasps \u4f7f\u7528\u4e86\u4e24\u7ea7\u795e\u7ecf\u7f51\u7edc\u751f\u6210\u6293\u53d6\u6846 \u8bba\u6587 A Vision-based Robotic Grasping System Using Deep Learning for 3D Object Recognition and Pose Estimation \u5bf95\u4e2a\u5bf9\u50cf\u5efa\u7acb\u4e86\u6570\u636e\u96c6\uff0c\u91c7\u7528\u4e00\u4e2aCNN\u7f51\u7edc\u68c0\u6d4b\u5bf9\u50cf\u7684\u4f4d\u7f6e\u548c\u4f30\u8ba1\u59ff\u6001\uff0c\u6700\u540e\u6267\u884c\u6293\u53d6\u3002 MIT\u7684\u4e00\u7bc7 \u8bba\u6587 \u91c7\u7528SegNet\u7f51\u7edc\u4eceRGB\u56fe\u50cf\u4e2d\u5206\u5272\u51fa\u5bf9\u50cf\u7684\u63a9\u6a21Mask\uff0c\u518d\u7528\u8be5\u63a9\u6a21\u4ece\u70b9\u4e91\u56fe\u50cf\u4e2d\u5206\u5272\u51fa\u5bf9\u50cf\u70b9\u4e91\uff0c\u518d\u518d\u6839\u636e\u5206\u5272\u51fa\u7684\u5bf9\u8c61\u70b9\u4e91\u4ece\u6a21\u578b\u5e93\u4e2d\u627e\u51fa\u4e0e\u4e4b\u5339\u914d\u7684\u6a21\u578b\uff0c\u8fdb\u800c\u8ba1\u7b97\u6a21\u578b\u7684\u65cb\u8f6c\u89d2\u5ea6\uff0c\u6700\u540e\u6267\u884c\u6293\u53d6\u4efb\u52a1\u3002 \u8bba\u6587\u8fd8\u6ca1\u770b","title":"\u6587\u732e\u603b\u8ff0"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/0/#_1","text":"\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u673a\u5668\u4eba\u6293\u53d6\uff0c\u76ee\u524d(20190803 21:50)\u770b\u4e86USA\u4e1c\u5317\u5927\u5b66Helping Hands\u5b9e\u9a8c\u5ba4\u7684 \u8bba\u6587 \u505a\u7684\u7a0d\u597d\u4e00\u4e9b\uff0c\u5b9e\u9a8c\u5ba4\u7684\u5de5\u4f5c\u6709\u5ef6\u7eed\u6027\uff0c\u4ee3\u7801\u516c\u5f00\uff08\u505a\u6210\u4e86ROS\u529f\u80fd\u5305\uff09\u3002\u8fd1\u4e24\u5e74\u7684\u8bba\u6587\u5b9e\u9a8c\u7ed3\u679c\u770b\u8d77\u6765\u8fd8\u4e0d\u9519\u3002\u4f46\u662f\u8fd9\u4e2a\u5b9e\u9a8c\u5ba4\u5199\u7684\u8bba\u6587\u5f88\u559c\u6b22\u7528\u6570\u5b66\u7b26\u53f7\u5b9a\u4e49\u4e00\u4e9b\u6982\u5ff5\uff0c\u5bfc\u81f4\u6574\u7bc7\u8bba\u6587\u770b\u4e0a\u53bb\u5168\u90e8\u662f\u516c\u5f0f\uff0c\u8ba9\u6211\u770b\u5f97\u8111\u58f3\u75bc\u3002 \u8bba\u6587 Deep Learning for Detecting Robotic Grasps \u4f7f\u7528\u4e86\u4e24\u7ea7\u795e\u7ecf\u7f51\u7edc\u751f\u6210\u6293\u53d6\u6846 \u8bba\u6587 A Vision-based Robotic Grasping System Using Deep Learning for 3D Object Recognition and Pose Estimation \u5bf95\u4e2a\u5bf9\u50cf\u5efa\u7acb\u4e86\u6570\u636e\u96c6\uff0c\u91c7\u7528\u4e00\u4e2aCNN\u7f51\u7edc\u68c0\u6d4b\u5bf9\u50cf\u7684\u4f4d\u7f6e\u548c\u4f30\u8ba1\u59ff\u6001\uff0c\u6700\u540e\u6267\u884c\u6293\u53d6\u3002 MIT\u7684\u4e00\u7bc7 \u8bba\u6587 \u91c7\u7528SegNet\u7f51\u7edc\u4eceRGB\u56fe\u50cf\u4e2d\u5206\u5272\u51fa\u5bf9\u50cf\u7684\u63a9\u6a21Mask\uff0c\u518d\u7528\u8be5\u63a9\u6a21\u4ece\u70b9\u4e91\u56fe\u50cf\u4e2d\u5206\u5272\u51fa\u5bf9\u50cf\u70b9\u4e91\uff0c\u518d\u518d\u6839\u636e\u5206\u5272\u51fa\u7684\u5bf9\u8c61\u70b9\u4e91\u4ece\u6a21\u578b\u5e93\u4e2d\u627e\u51fa\u4e0e\u4e4b\u5339\u914d\u7684\u6a21\u578b\uff0c\u8fdb\u800c\u8ba1\u7b97\u6a21\u578b\u7684\u65cb\u8f6c\u89d2\u5ea6\uff0c\u6700\u540e\u6267\u884c\u6293\u53d6\u4efb\u52a1\u3002 \u8bba\u6587\u8fd8\u6ca1\u770b","title":"\u603b\u8ff0"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/1/","text":"\u57fa\u4e8e\u89c6\u89c9\u7684\u673a\u5668\u4eba\u6293\u53d6\u7cfb\u7edf\u91c7\u7528\u6df1\u5ea6\u5b66\u4e60\u68c0\u6d4b3D\u7269\u4f53\u7684\u4f4d\u59ff \u00b6 A Vision-based Robotic Grasping System Using Deep Learning for 3D Object Recognition and Pose Estimation 2013-ROBIO\u56fd\u9645\u4f1a\u8bae-\u5e7f\u4e1c\u4ec0\u4e48\u5b9e\u9a8c\u5ba4 1)\u6458\u8981 \u00b6 \u91c7\u7528\u6700\u6d41\u884c\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u662f\u5177\u6709\u6700\u5927\u6c60\u5316\u5c42\u7684CNN\u6a21\u578b\uff0c\u4e14\u628a\u6293\u53d6\u5bf9\u8c61\u7684\u4e0d\u540c\u4f4d\u59ff\u5206\u4e3a\u4e0d\u540c\u7684\u7c7b\u3002 \u63d0\u51fa\u4e86\u4e00\u4e2a\u5bf9\u8c61\u68c0\u6d4b\u65b9\u6cd5\u7528\u4e8e\u514b\u670d\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u7f3a\u70b9 \u6784\u5efa\u4e86\u6570\u636e\u96c6\uff0c\u6570\u636e\u96c6\u5305\u542b5\u4e2a\u5bf9\u8c61\u7684\u4e0d\u540c\u4f4d\u59ff \u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8bba\u6587\u4e2d\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u4ee5\u5f88\u597d\u5730\u8bc6\u522b\u5bf9\u8c61\u548c\u5bf9\u8c61\u7684\u4f4d\u59ff 2\uff09Introduction \u00b6 \u7814\u7a76\u8005\u7684\u68a6\u60f3\uff1a\u5b9e\u73b0\u9ad8\u667a\u80fd\u7684\u673a\u5668\u4eba \u5217\u4e3e\u4e86\u597d\u51e0\u7bc7\u6587\u732e\u5e76\u62a8\u51fb\u4ed6\u4eec\u7684\u65b9\u6cd5\u4e0d\u884c\uff0c\u8981\u4e48\u662f\u9700\u8981\u7279\u522b\u660e\u663e\u533a\u5206\u7279\u5f81\u7684\u8bc6\u522b\u65b9\u6cd5\uff0c\u8981\u4e48\u662f\u4e0d\u80fd\u6b63\u786e\u68c0\u6d4b\u5bf9\u8c61\u7684\u65b9\u6cd5\uff0c\u6216\u8005\u57283D\u6570\u636e\u4e0a\u57fa\u4e8e\u8fb9\u7f18\u6216\u8868\u9762\u7684\u68c0\u6d4b\u65b9\u6cd5\u6613\u53d7\u566a\u58f0\u7684\u5e72\u6270 \u672c\u8bba\u6587\u4e2d\u63d0\u51fa\u7684\u7cfb\u7edf\u7ed3\u6784\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e0d\u4ec5\u53ef\u4ee5\u8bc6\u522b\u7269\u4f53\uff0c\u800c\u4e14\u8fd8\u53ef\u4ee5\u4f30\u8ba1\u5176\u59ff\u6001\uff0c\u7cfb\u7edf\u7ed3\u6784\u5982\u56fe\u6240\u793a\uff1a 3\uff09Object detection \u00b6 \u628a\u56fe\u50cf\u4f20\u9001\u7ed9\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e4b\u524d\uff0c\u5148\u91c7\u7528\u8bba\u6587\u4e2d\u63d0\u51fa\u7684\u524d\u666f\u5206\u5272\u65b9\u6cd5**\u57fa\u4e8e\u5b57\u5178\u7684K\u5747\u503c\u805a\u7c7b\u65b9\u6cd5**\u4ece\u539f\u59cb\u56fe\u50cf\u4e2d\u5206\u5272\u51fa\u524d\u666f\u7269\u4f53\u3002 \u8fd9\u4e2a\u5177\u4f53\u5b9e\u73b0\u65b9\u6cd5\u6211\u6ca1\u770b Object Recognition and Pose Estimation with MPCNN \u00b6 MPCNN\uff1a\u5c31\u662f\u666e\u901a\u5177\u6709\u6700\u5927\u6c60\u5316\u5c42\u7684CNN\u6a21\u578b\uff0c\u8bba\u6587\u4e2d\u4f7f\u7528\u7684\u662f\u7c7b\u4f3c\u4e8eLeNet5\u7684\u6a21\u578b\u7ed3\u6784 \u6a21\u578b\u7ed3\u6784 \u5982\u4f55\u8bc6\u522b\u5bf9\u8c61\u7684\u7c7b\u522b\u548c\u4f4d\u59ff\u7684\u5462 \uff1a\u8bba\u6587\u4e2d\u4f7f\u7528\u7684\u6570\u636e\u96c6\u53ea\u5305\u542b5\u4e2a\u4e0d\u540c\u7684\u5bf9\u8c61\uff0c\u6bcf\u4e2a\u5bf9\u8c61\u5728\u6c34\u5e73\u9762\u5185\u4e0d\u540c\u89d2\u5ea6\u53c8\u5206\u6210\u4e0d\u540c\u7684\u7c7b\u522b\u3002\u6bd4\u5982\u76d2\u5b50\u5bf9\u8c61\u6bcf30\u00b0\u5206\u6210\u4e00\u4e2a\u7c7b\uff0c\u76d2\u5b50\u5c31\u53606\u7c7b\uff0c\u4f5c\u4e3a\u6a21\u578b\u6700\u540e\u4e00\u5c42\u8f93\u51fa\u7684\u524d6\u4e2a\u795e\u7ecf\u5143\uff0c\u8fd9\u6837\u5c31\u53ef\u4ee5\u6839\u636e\u662f\u54ea\u4e00\u4e2a\u795e\u7ecf\u5143\u5e76\u5224\u65ad\u51fa\u662f\u54ea\u4e2a\u5bf9\u8c61\u7684\u54ea\u4e2a\u4f4d\u59ff\u3002 4\uff09Experiment \u00b6 \u5b9e\u9a8c\u5e73\u53f0\uff1aBasler\u76f8\u673a\u548c\u5149\u6e90+\u673a\u5668\u4eba \u6570\u636e\u96c6 \u00b6 \u6570\u636e\u96c6\u603b\u5171\u4ec5\u4ec5\u53ea\u67095\u4e2a\u5bf9\u8c61 \u8bad\u7ec3\u96c6\uff1a1600\u5f20 \u6d4b\u8bd5\u96c61\uff1a1980\u5f20 \u6d4b\u8bd5\u96c62\uff1a924\u5f20 \u5bf9\u8c61\u8bc6\u522b\u7ed3\u679c \u00b6 \u6d4b\u8bd5\u96c6\u7cbe\u5ea6\uff1a94.5% \u548c 98.9% \u673a\u5668\u4eba\u6293\u53d6 \u00b6","title":"\u57fa\u4e8e\u89c6\u89c9\u7684\u673a\u5668\u4eba\u6293\u53d6\u7cfb\u7edf\u91c7\u7528\u6df1\u5ea6\u5b66\u4e60\u68c0\u6d4b3D\u7269\u4f53\u7684\u4f4d\u59ff"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/1/#3d","text":"A Vision-based Robotic Grasping System Using Deep Learning for 3D Object Recognition and Pose Estimation 2013-ROBIO\u56fd\u9645\u4f1a\u8bae-\u5e7f\u4e1c\u4ec0\u4e48\u5b9e\u9a8c\u5ba4","title":"\u57fa\u4e8e\u89c6\u89c9\u7684\u673a\u5668\u4eba\u6293\u53d6\u7cfb\u7edf\u91c7\u7528\u6df1\u5ea6\u5b66\u4e60\u68c0\u6d4b3D\u7269\u4f53\u7684\u4f4d\u59ff"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/1/#1","text":"\u91c7\u7528\u6700\u6d41\u884c\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u662f\u5177\u6709\u6700\u5927\u6c60\u5316\u5c42\u7684CNN\u6a21\u578b\uff0c\u4e14\u628a\u6293\u53d6\u5bf9\u8c61\u7684\u4e0d\u540c\u4f4d\u59ff\u5206\u4e3a\u4e0d\u540c\u7684\u7c7b\u3002 \u63d0\u51fa\u4e86\u4e00\u4e2a\u5bf9\u8c61\u68c0\u6d4b\u65b9\u6cd5\u7528\u4e8e\u514b\u670d\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u7f3a\u70b9 \u6784\u5efa\u4e86\u6570\u636e\u96c6\uff0c\u6570\u636e\u96c6\u5305\u542b5\u4e2a\u5bf9\u8c61\u7684\u4e0d\u540c\u4f4d\u59ff \u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8bba\u6587\u4e2d\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u4ee5\u5f88\u597d\u5730\u8bc6\u522b\u5bf9\u8c61\u548c\u5bf9\u8c61\u7684\u4f4d\u59ff","title":"1)\u6458\u8981"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/1/#2introduction","text":"\u7814\u7a76\u8005\u7684\u68a6\u60f3\uff1a\u5b9e\u73b0\u9ad8\u667a\u80fd\u7684\u673a\u5668\u4eba \u5217\u4e3e\u4e86\u597d\u51e0\u7bc7\u6587\u732e\u5e76\u62a8\u51fb\u4ed6\u4eec\u7684\u65b9\u6cd5\u4e0d\u884c\uff0c\u8981\u4e48\u662f\u9700\u8981\u7279\u522b\u660e\u663e\u533a\u5206\u7279\u5f81\u7684\u8bc6\u522b\u65b9\u6cd5\uff0c\u8981\u4e48\u662f\u4e0d\u80fd\u6b63\u786e\u68c0\u6d4b\u5bf9\u8c61\u7684\u65b9\u6cd5\uff0c\u6216\u8005\u57283D\u6570\u636e\u4e0a\u57fa\u4e8e\u8fb9\u7f18\u6216\u8868\u9762\u7684\u68c0\u6d4b\u65b9\u6cd5\u6613\u53d7\u566a\u58f0\u7684\u5e72\u6270 \u672c\u8bba\u6587\u4e2d\u63d0\u51fa\u7684\u7cfb\u7edf\u7ed3\u6784\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e0d\u4ec5\u53ef\u4ee5\u8bc6\u522b\u7269\u4f53\uff0c\u800c\u4e14\u8fd8\u53ef\u4ee5\u4f30\u8ba1\u5176\u59ff\u6001\uff0c\u7cfb\u7edf\u7ed3\u6784\u5982\u56fe\u6240\u793a\uff1a","title":"2\uff09Introduction"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/1/#3object-detection","text":"\u628a\u56fe\u50cf\u4f20\u9001\u7ed9\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e4b\u524d\uff0c\u5148\u91c7\u7528\u8bba\u6587\u4e2d\u63d0\u51fa\u7684\u524d\u666f\u5206\u5272\u65b9\u6cd5**\u57fa\u4e8e\u5b57\u5178\u7684K\u5747\u503c\u805a\u7c7b\u65b9\u6cd5**\u4ece\u539f\u59cb\u56fe\u50cf\u4e2d\u5206\u5272\u51fa\u524d\u666f\u7269\u4f53\u3002 \u8fd9\u4e2a\u5177\u4f53\u5b9e\u73b0\u65b9\u6cd5\u6211\u6ca1\u770b","title":"3\uff09Object detection"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/1/#object-recognition-and-pose-estimation-with-mpcnn","text":"MPCNN\uff1a\u5c31\u662f\u666e\u901a\u5177\u6709\u6700\u5927\u6c60\u5316\u5c42\u7684CNN\u6a21\u578b\uff0c\u8bba\u6587\u4e2d\u4f7f\u7528\u7684\u662f\u7c7b\u4f3c\u4e8eLeNet5\u7684\u6a21\u578b\u7ed3\u6784 \u6a21\u578b\u7ed3\u6784 \u5982\u4f55\u8bc6\u522b\u5bf9\u8c61\u7684\u7c7b\u522b\u548c\u4f4d\u59ff\u7684\u5462 \uff1a\u8bba\u6587\u4e2d\u4f7f\u7528\u7684\u6570\u636e\u96c6\u53ea\u5305\u542b5\u4e2a\u4e0d\u540c\u7684\u5bf9\u8c61\uff0c\u6bcf\u4e2a\u5bf9\u8c61\u5728\u6c34\u5e73\u9762\u5185\u4e0d\u540c\u89d2\u5ea6\u53c8\u5206\u6210\u4e0d\u540c\u7684\u7c7b\u522b\u3002\u6bd4\u5982\u76d2\u5b50\u5bf9\u8c61\u6bcf30\u00b0\u5206\u6210\u4e00\u4e2a\u7c7b\uff0c\u76d2\u5b50\u5c31\u53606\u7c7b\uff0c\u4f5c\u4e3a\u6a21\u578b\u6700\u540e\u4e00\u5c42\u8f93\u51fa\u7684\u524d6\u4e2a\u795e\u7ecf\u5143\uff0c\u8fd9\u6837\u5c31\u53ef\u4ee5\u6839\u636e\u662f\u54ea\u4e00\u4e2a\u795e\u7ecf\u5143\u5e76\u5224\u65ad\u51fa\u662f\u54ea\u4e2a\u5bf9\u8c61\u7684\u54ea\u4e2a\u4f4d\u59ff\u3002","title":"Object Recognition and Pose Estimation with MPCNN"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/1/#4experiment","text":"\u5b9e\u9a8c\u5e73\u53f0\uff1aBasler\u76f8\u673a\u548c\u5149\u6e90+\u673a\u5668\u4eba","title":"4\uff09Experiment"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/1/#_1","text":"\u6570\u636e\u96c6\u603b\u5171\u4ec5\u4ec5\u53ea\u67095\u4e2a\u5bf9\u8c61 \u8bad\u7ec3\u96c6\uff1a1600\u5f20 \u6d4b\u8bd5\u96c61\uff1a1980\u5f20 \u6d4b\u8bd5\u96c62\uff1a924\u5f20","title":"\u6570\u636e\u96c6"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/1/#_2","text":"\u6d4b\u8bd5\u96c6\u7cbe\u5ea6\uff1a94.5% \u548c 98.9%","title":"\u5bf9\u8c61\u8bc6\u522b\u7ed3\u679c"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/1/#_3","text":"","title":"\u673a\u5668\u4eba\u6293\u53d6"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/2/","text":"Deep Learning for Detecting Robotic Grasps \u00b6 2014\u5e74 Cornell\u5927\u5b66 1\uff09Introduction \u00b6 \u8d21\u732e\uff1a \u63a8\u51fa\u673a\u5668\u4eba\u6293\u53d6\u68c0\u6d4b\u6df1\u5ea6\u5b66\u4e60\u7b97\u6cd5\uff0c\u8bba\u6587\u91cc\u8bf4\u4ed6\u4eec\u662f\u7b2c\u4e00\u4e2a\u505a\u8fd9\u4e2a\u65b9\u5411\u7684 \u63a8\u51fa\u7ed3\u6784\u5316regularization\u65b9\u6cd5\u5904\u7406multimodal data,\u5c31\u662f\u591a\u79cd\u7c7b\u578b\u7684\u6570\u636e\u4f5c\u4e3a\u8f93\u5165\u5c31\u662f\u591a\u6a21\u6001\u6570\u636e\uff0c\u5982\u6587\u5b57\u548c\u56fe\u50cf\u3001\u97f3\u9891\u548c\u89c6\u9891\u3001RGB\u548c\u6df1\u5ea6\u56fe\u3002 \u63a8\u51fa\u4e24\u9636\u6bb5\u7ea7\u8054\u68c0\u6d4b\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u663e\u8457\u7684\u7f29\u77ed\u4e86\u8ba1\u7b97\u6d88\u8017 \u5728baxter\u53cc\u81c2\u673a\u5668\u4eba\u548cPR2\u673a\u5668\u4eba\u4e0a\u505a\u5b9e\u9a8c\uff0c\u5206\u522b\u5f97\u523084%\u548c89%\u7684\u6293\u53d6\u6210\u529f\u7387 2\uff09Related work \u00b6 A . Robotic grasping:\u4f5c\u8005\u63a8\u8350\u9605\u8bfb\u7684\u6587\u732e: 1 2 3 4 5 6 7 8 9 \uff081\uff09grasp\u7684\u5b9a\u4e49\uff1a \uff082\uff09Grasping for 3D Model\uff1a\u5217\u4e3e\u4e86\u5f88\u591a\u6587\u732e\u8bf4\u660e\u57fa\u4e8e3D Model\u7684\u6293\u53d6\u7b56\u7565\u9700\u8981\u5bf9\u8c61\u5b8c\u6574\u76843D\u4fe1\u606f \uff083\uff09Sensing for grasping\uff1a\u5217\u4e3e\u6587\u732e\uff0c\u5982\u4f55\u83b7\u53d6\u5bf9\u8c61\u7684\u6293\u53d6\u4fe1\u606f\uff08\u4f4d\u59ff\uff09\uff0c\u53cd\u6b63\u5c31\u662f\u5f88\u96be\u76f4\u63a5\u83b7\u53d6\u5230\u6293\u53d6\u4f4d\u59ff \uff084\uff09Learning for grasping\uff1a\u628a\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\u5e94\u7528\u5230\u6293\u53d6\u4e2d\uff0c\u53ef\u4ee5\u751f\u6210\u7cfb\u7edf\u672a\u89c1\u8fc7\u7684\u7269\u4f53\u6293\u53d6\u4f4d\u59ff \uff085\uff09Other Application with RGBD Data\uff1a B. Deep Learning DL for Detection:\u5217\u4e3e\u4e86\u5f88\u591a\u6587\u732e\u8bf4\u7269\u4f53\u68c0\u6d4b\uff0c\u884c\u4eba\u68c0\u6d4b\uff0c\u8fd9\u4e9b\u90fd\u662f\u83b7\u53d6\u7269\u4f53\u7684\u5305\u56f4\u76d2\u3002\u800c\u5bf9\u4e8e\u4e00\u4e2a\u6293\u53d6\u5bf9\u8c61\u6765\u8bf4\uff0c\u6293\u53d6\u6846\u4e0d\u6b62\u4e00\u4e2a\uff0c\u9700\u8981\u4ece\u8fd9\u4e9b\u6293\u53d6\u6846\u4e2d\u9009\u51fa\u6700\u597d\u7684\u4e00\u4e2a\u3002 Multimodal DL:\u666e\u901a\u7684\u65b9\u6cd5\u662f\u5355\u72ec\u5b66\u4e60\u6bcf\u4e2a\u4f4e\u5c42\u7684\u7279\u5f81\u6570\u636e\u6216\u8005\u7b80\u5355\u7ea7\u8054\u6bcf\u4e2a\u7c7b\u578b\u7684\u6570\u636e\u540e\u518d\u8fdb\u884c\u5b66\u4e60\u3002\u800c\u5728\u672c\u7bc7\u8bba\u6587\u4e2d\u91c7\u7528\u7ed3\u6784\u5316\u6b63\u5219\u65b9\u6cd5\u8fdb\u884c\u5b66\u4e60\u3002 3\uff09DL for grasp detection: system and model \u00b6 1 \u6293\u53d6\u65b9\u5411\u77e9\u5f62\u7684\u5b9a\u4e49\uff1a\uff08x, y, height, width, angle\uff09 \u7cfb\u7edf\u6a21\u578b\u7684\u7ed3\u6784 \u4e24\u9636\u6bb5\u751f\u6210grasp\u793a\u610f\u56fe \u6a21\u578b\u4e2d\u7684\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784","title":"Deep Learning for Detecting Robotic Grasps"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/2/#deep-learning-for-detecting-robotic-grasps","text":"2014\u5e74 Cornell\u5927\u5b66","title":"Deep Learning for Detecting Robotic Grasps"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/2/#1introduction","text":"\u8d21\u732e\uff1a \u63a8\u51fa\u673a\u5668\u4eba\u6293\u53d6\u68c0\u6d4b\u6df1\u5ea6\u5b66\u4e60\u7b97\u6cd5\uff0c\u8bba\u6587\u91cc\u8bf4\u4ed6\u4eec\u662f\u7b2c\u4e00\u4e2a\u505a\u8fd9\u4e2a\u65b9\u5411\u7684 \u63a8\u51fa\u7ed3\u6784\u5316regularization\u65b9\u6cd5\u5904\u7406multimodal data,\u5c31\u662f\u591a\u79cd\u7c7b\u578b\u7684\u6570\u636e\u4f5c\u4e3a\u8f93\u5165\u5c31\u662f\u591a\u6a21\u6001\u6570\u636e\uff0c\u5982\u6587\u5b57\u548c\u56fe\u50cf\u3001\u97f3\u9891\u548c\u89c6\u9891\u3001RGB\u548c\u6df1\u5ea6\u56fe\u3002 \u63a8\u51fa\u4e24\u9636\u6bb5\u7ea7\u8054\u68c0\u6d4b\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u663e\u8457\u7684\u7f29\u77ed\u4e86\u8ba1\u7b97\u6d88\u8017 \u5728baxter\u53cc\u81c2\u673a\u5668\u4eba\u548cPR2\u673a\u5668\u4eba\u4e0a\u505a\u5b9e\u9a8c\uff0c\u5206\u522b\u5f97\u523084%\u548c89%\u7684\u6293\u53d6\u6210\u529f\u7387","title":"1\uff09Introduction"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/2/#2related-work","text":"A . Robotic grasping:\u4f5c\u8005\u63a8\u8350\u9605\u8bfb\u7684\u6587\u732e: 1 2 3 4 5 6 7 8 9 \uff081\uff09grasp\u7684\u5b9a\u4e49\uff1a \uff082\uff09Grasping for 3D Model\uff1a\u5217\u4e3e\u4e86\u5f88\u591a\u6587\u732e\u8bf4\u660e\u57fa\u4e8e3D Model\u7684\u6293\u53d6\u7b56\u7565\u9700\u8981\u5bf9\u8c61\u5b8c\u6574\u76843D\u4fe1\u606f \uff083\uff09Sensing for grasping\uff1a\u5217\u4e3e\u6587\u732e\uff0c\u5982\u4f55\u83b7\u53d6\u5bf9\u8c61\u7684\u6293\u53d6\u4fe1\u606f\uff08\u4f4d\u59ff\uff09\uff0c\u53cd\u6b63\u5c31\u662f\u5f88\u96be\u76f4\u63a5\u83b7\u53d6\u5230\u6293\u53d6\u4f4d\u59ff \uff084\uff09Learning for grasping\uff1a\u628a\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\u5e94\u7528\u5230\u6293\u53d6\u4e2d\uff0c\u53ef\u4ee5\u751f\u6210\u7cfb\u7edf\u672a\u89c1\u8fc7\u7684\u7269\u4f53\u6293\u53d6\u4f4d\u59ff \uff085\uff09Other Application with RGBD Data\uff1a B. Deep Learning DL for Detection:\u5217\u4e3e\u4e86\u5f88\u591a\u6587\u732e\u8bf4\u7269\u4f53\u68c0\u6d4b\uff0c\u884c\u4eba\u68c0\u6d4b\uff0c\u8fd9\u4e9b\u90fd\u662f\u83b7\u53d6\u7269\u4f53\u7684\u5305\u56f4\u76d2\u3002\u800c\u5bf9\u4e8e\u4e00\u4e2a\u6293\u53d6\u5bf9\u8c61\u6765\u8bf4\uff0c\u6293\u53d6\u6846\u4e0d\u6b62\u4e00\u4e2a\uff0c\u9700\u8981\u4ece\u8fd9\u4e9b\u6293\u53d6\u6846\u4e2d\u9009\u51fa\u6700\u597d\u7684\u4e00\u4e2a\u3002 Multimodal DL:\u666e\u901a\u7684\u65b9\u6cd5\u662f\u5355\u72ec\u5b66\u4e60\u6bcf\u4e2a\u4f4e\u5c42\u7684\u7279\u5f81\u6570\u636e\u6216\u8005\u7b80\u5355\u7ea7\u8054\u6bcf\u4e2a\u7c7b\u578b\u7684\u6570\u636e\u540e\u518d\u8fdb\u884c\u5b66\u4e60\u3002\u800c\u5728\u672c\u7bc7\u8bba\u6587\u4e2d\u91c7\u7528\u7ed3\u6784\u5316\u6b63\u5219\u65b9\u6cd5\u8fdb\u884c\u5b66\u4e60\u3002","title":"2\uff09Related work"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/2/#3dl-for-grasp-detection-system-and-model","text":"1 \u6293\u53d6\u65b9\u5411\u77e9\u5f62\u7684\u5b9a\u4e49\uff1a\uff08x, y, height, width, angle\uff09 \u7cfb\u7edf\u6a21\u578b\u7684\u7ed3\u6784 \u4e24\u9636\u6bb5\u751f\u6210grasp\u793a\u610f\u56fe \u6a21\u578b\u4e2d\u7684\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784","title":"3\uff09DL for grasp detection: system and model"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/3/","text":"Using Geometry to Detect Grasp Poses in 3D Point Clouds \u00b6 2015 \u7f8e\u56fd\u4e1c\u5317\u5927\u5b66 \u8ba1\u7b97\u673a\u4fe1\u606f\u79d1\u5b66\u5b66\u9662 Boston\uff0cMassachusetts\uff0cUSA \u8be5\u5b9e\u9a8c\u5ba4 (Helping Hands Lab) \u53c8\u53d1\u8868\u4e86\u51e0\u7bc7\u6293\u53d6\u7684\u8bba\u6587\uff0c \u4f5c\u8005Andreas ten Pas\u7684\u4e2a\u4eba\u7f51\u7ad9 1\uff09\u6458\u8981 \u00b6 \u8bba\u6587\u63d0\u51fa\u4e86\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u6742\u4e71\u573a\u666f\u4e2d\u68c0\u6d4b\u65b0\u7269\u4f53\u7684\u6293\u53d6\u4f4d\u59ff\uff0c\u7b97\u6cd5\u7684\u8f93\u5165\u662f\u7269\u4f53\u7684\u70b9\u4e91\u548c\u673a\u5668\u4eba\u7684\u51e0\u4f55\u53c2\u6570\uff0c\u7b97\u6cd5\u7684\u8f93\u51fa\u662f\u4e00\u7cfb\u5217\u7684\u53ef\u4ee5\u5b9e\u73b0\u6293\u53d6\u7684\u4f4d\u59ff\u3002 \u8d21\u732e\u70b9\uff1a \uff081\uff09\u5bf9\u4e00\u4e2a\u6293\u53d6\u4f4d\u59ff\u5b9a\u4e49\u4e86\u4e00\u7cfb\u5217\u7684\u5fc5\u8981\u7684\u51e0\u4f55\u9650\u5b9a\u6761\u4ef6 (geometric grasp conditions) \uff0c\u8fd9\u4e9b\u9650\u5b9a\u6761\u4ef6\u53ef\u7528\u4e8e\u751f\u6210\u4e00\u7cfb\u5217\u7684\u5019\u9009\u6293\u53d6\u4f4d\u59ff (grasp hypotheses) \uff0c\u8fd9\u4f7f\u6211\u4eec\u7684\u5173\u6ce8\u70b9\u96c6\u4e2d\u5728\u53ef\u751f\u6210\u6293\u53d6\u4f4d\u59ff\u7684\u533a\u57df\u3002 \uff082\uff09\u9610\u8ff0\u4e86\u5982\u4f55\u4f7f\u7528geometric grasp conditions\u7528\u4e8e\u751f\u6210\u7528\u4e8e\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u6807\u8bb0\u6570\u636e\u96c6\u3002 \uff083\uff09\u8bba\u6587\u4e2d\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u5355\u4e2a\u7269\u4f53\u573a\u666f\u4e0b\u53d6\u5f9788%\u7684\u5e73\u5747\u6210\u529f\u7387\uff0c\u5728\u6742\u4e71\u80cc\u666f\u4e0b\u53d6\u5f9773%\u7684\u5e73\u5747\u6210\u529f\u7387\u3002 3. \u8bba\u6587\u4ee3\u7801\u5df2\u7ecf\u505a\u6210\u4e86ROS\u529f\u80fd\u5305\uff0c\u94fe\u63a5\uff1a http://wiki.ros.org/agile_grasp 2\uff09Introduction \u00b6 \u4f5c\u8005\u628a\u673a\u5668\u4eba\u6293\u53d6\u5206\u6210\u4e24\u6b65\uff0c\u4f20\u7edf\u5730\u5206\u6210perception\u548cplanning\u3002Perception\u662f\u4f30\u8ba1\u88ab\u6293\u53d6\u5bf9\u8c61\u7684\u4f4d\u7f6e\u548c\u59ff\u6001\uff0c\u4e4b\u540e\u624d\u662f\u89c4\u5212\u8def\u5f84\u548c\u63a7\u5236\u673a\u5668\u4eba\u5b9e\u73b0\u6293\u53d6\u3002 \u96be\u70b9\u5c31\u5728\u4e8e\u5982\u4f55\u4f30\u8ba1\u6293\u53d6\u5bf9\u8c61\u7684\u4f4d\u59ff\u3002 \u7814\u7a76\u8005\u5df2\u7ecf\u63d0\u51fa\u4e86\u591a\u79cd\u6293\u53d6\u70b9\u68c0\u6d4b\u65b9\u6cd5\u3002\u5176\u4e2d\u4e00\u7c7b\u662f\u4eceRGBD\u6570\u636e\u4e2d\u4f7f\u7528\u6ed1\u7a97\u6cd5\uff08sliding window\uff09\u68c0\u6d4b\u6293\u53d6\u533a\u57df\uff0c\u53e6\u4e00\u4e9b\u65b9\u6cd5\u91c7\u7528\u4eba\u5de5\u5b9a\u4e49\u7684\u6293\u53d6\u4f4d\u59ff\u63cf\u8ff0\uff08grasp prototypes\uff09 \u4ee5\u4e0a\u6240\u8bf4\u4e24\u79cd\u65b9\u6cd5\u6ca1\u6709\u5173\u6ce8grasp geometry\uff0c\u70b9\u4e91\u6570\u636e\u53ef\u4ee5\u5e2e\u52a9\u7814\u7a76grasp geometry\u3002\u672c\u8bba\u6587\u4e2d\u7b97\u6cd5\u901a\u8fc7\u9884\u6d4b\u5f53\u524d\u573a\u666f\u4e0b\u5b58\u5728\u6240\u9700\u4e14\u8db3\u591f\u7684\u51e0\u4f55\u6761\u4ef6\u4ece\u800c\u751f\u6210\u6293\u53d6\u4f4d\u59ff\u3002 \u7b97\u6cd5\u5206\u6210\u4e24\u6b65: \uff081\uff09\u751f\u6210\u5927\u91cf\u7684\u540e\u5019\u9009\u6293\u53d6\u4f4d\u59ff\uff08grasp hypothesis\uff09\u3002\u9996\u5148\u7528\u51e0\u4f55\u4fe1\u606f\u51cf\u5c11\u91c7\u6837\u533a\u57df\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u91c7\u6837\u65b9\u6cd5\u751f\u6210grasp hypotheses, \u540c\u65f6\u6ee1\u8db3\u673a\u5668\u624b\u4e0e\u6293\u53d6\u5bf9\u50cf\u4e4b\u95f4\u4e0d\u53d1\u751f\u78b0\u649e\u548c\u673a\u68b0\u624b\u6293\u5fc5\u987b\u8986\u76d6\u5728\u5bf9\u50cf\u7684\u8868\u9762\u3002\u7b2c\u4e8c\u6b65\u7b97\u6cd5\u4f7f\u7528\u51e0\u4f55\u4fe1\u606f\u81ea\u52a8\u5730\u6807\u8bb0\u8bad\u7ec3\u6570\u636e\u96c6\u3002 \uff082\uff09\u5bf9\u751f\u6210\u7684\u5019\u9009\u6293\u53d6\u4f4d\u59ff\u8fdb\u884c\u5206\u7c7b \u5b9e\u9a8c\u663e\u793a\u8bba\u6587\u4e2d\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u4e0d\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u60c5\u51b5\u4e0b\u6293\u53d6\u65b0\u5bf9\u50cf\u53ef\u4ee5\u83b7\u5f9773%\u7684\u6210\u529f\u7387\u3002\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u4e4b\u540e\u6210\u529f\u7387\u4e0a\u5347\u523088%\u3002 \u4e14\u8bba\u6587\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u975e\u5e38\u6742\u4e71\u7684\u573a\u666f\u4e0b\u4ecd\u53ef\u53d6\u5f9773%\u7684\u5e73\u5747\u6210\u529f\u7387\u3002 3\uff09Related Work \u00b6 \u6293\u53d6\u70b9\u8bc6\u522b\u65b9\u6cd5\uff0c\u6700\u5f00\u59cb\u5728RGBD\u56fe\u50cf\u4e2d\u4f7f\u7528sliding window\u8bc6\u522b\u6293\u53d6\u533a\u57df\uff0c\u4e4b\u540e\u7814\u7a76\u8005\u5728\u8fd9\u57fa\u7840\u4e0a\u6269\u5c55\u8be5\u65b9\u6cd5\u5b9e\u73b0\u6293\u53d6\uff0c\u5e76\u53d6\u5f97\u4e00\u5b9a\u7684\u6293\u53d6\u6210\u529f\u7387\u3002\u522b\u7684\u4e00\u4e9b\u65b9\u6cd5\u662f\u57fa\u4e8e\u70b9\u4e91\u6570\u636e\uff08point cloud\uff09\u6216\u8005RGB\u6570\u636e\uff0c \u4e0d\u60f3\u4ed4\u7ec6\u770b\u4e86 4\uff09Approach \u00b6 \u5b9a\u4e491\uff1aAntipodoal: \u5b9a\u4e492\uff1aAntipodoal Hand:\u4e8c\u5e73\u884c\u624b\u6307\u7684\u59ff\u6001\uff0c\u59ff\u6001\u7684\u63a5\u89e6\u70b9\u4f7f\u4e8c\u6307\u95ed\u5408\u65f6\u529b\u7684\u65b9\u5411\u6cbf\u7740\u4e24\u63a5\u89e6\u70b9\u7684\u8fde\u7ebf\u4e0a \u7b97\u6cd5\u7684\u53ef\u8868\u793a\u4e3a\uff1a 5\uff09\u91c7\u6837\u6293\u53d6\u59ff\u6001Sampling Hands \uff08\u751f\u6210hand hypotheses\uff09 \u00b6 Geometry of the Hand and the Object Surface \u00b6 \u673a\u68b0\u624b\u722a\u7684\u53c2\u6570\u901a\u8fc7\u53c2\u6570\u5411\u91cf \\theta = (\\theta_l, \\theta_w, \\theta_d, \\theta_t) \\theta = (\\theta_l, \\theta_w, \\theta_d, \\theta_t) \u6765\u63cf\u8ff0\uff0c \\theta_t \\theta_t \u8868\u793a\u624b\u6307\u7684\u539a\u5ea6\uff0c\u5982\u4f55\u4e0b\u56fe\u6240\u793a\uff1a \u8bba\u6587\u4e2d\u5b9a\u4e49\u597d\u591a\u516c\u5f0f\u770b\u4e0d\u61c2\uff0c\u8fd8\u5f15\u7528\u4e86\u4e00\u4e9b\u65b9\u6cd5\u8fdb\u884c\u62df\u5408 Hand Sample Set \u00b6 \u751f\u6210\u4e00\u4e2a\u6570\u636e\u96c6 H H \uff0c\u8be5\u6570\u636e\u96c6\u5305\u542b\u8bb8\u591aantipodal hands (h\\in H) (h\\in H) , \u9996\u5148\u8981\u5b9a\u4e493\u4e2a\u9650\u5236\u6761\u4ef6 \u673a\u68b0\u624b\u722a\u4e0e\u70b9\u4e91\u4e4b\u95f4\u6ca1\u6709\u78b0\u649e \u624b\u722a\u95ed\u5408\u5e73\u9762(hand closing plane)\u5305\u542bp: p\\in C(h) p\\in C(h) \u624b\u722a\u7684\u95ed\u5408\u5e73\u9762\u548c\u7269\u4f53\u70b9\u4e91\u7684\u5207\u5e73\u9762(cutting plane)\u5e73\u884c \u7b97\u6cd5\u63cf\u8ff0\uff1a\u9700\u8981\u7528\u7684\u65f6\u5019\u518d\u8fd4\u56de\u6765\u4ed4\u7ec6\u770b 6\uff09Classifying Hand Hypotheses \u00b6 \u5728\u6b65\u9aa45\uff09\u4e2d\u751f\u6210\u4e86hand hypotheses\uff0c\u5728\u8fd9\u4e00\u6b65\u6839\u636e\u5176\u662f\u5426\u4e3aantipodal hand\u5bf9\u5b83\u8fdb\u884c\u5206\u7c7b\u3002\u6700\u7b80\u5355\u7684\u65b9\u6cd5\u662f\u53c2\u8003\u5bf9\u50cf\u8868\u9762\u7684\u70b9\u4e91\u6570\u636e\u6765\u68c0\u6d4bhand hypotheses\u662f\u5426\u6ee1\u8db3 \u59ff\u6001\u7684\u63a5\u89e6\u70b9\u4f7f\u4e8c\u6307\u95ed\u5408\u65f6\u529b\u7684\u65b9\u5411\u6cbf\u7740\u4e24\u63a5\u89e6\u70b9\u7684\u8fde\u7ebf\u4e0a \uff0c \u4f46\u662f\u5f88\u591a\u771f\u5b9e\u7684\u70b9\u4e91\u6570\u636e\u53ea\u80fd\u770b\u5230\u5bf9\u50cf\u7684\u90e8\u5206 \uff0c\u6309\u71674\uff09\u5b9a\u4e492\u7684\u8981\u6c42\u6765\u68c0\u6d4bhand hypotheses\uff0c\u5219\u5f88\u5927\u90e8\u5206\u4e0d\u6ee1\u8db3\u8981\u6c42\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u8bba\u6587\u4e2d\u5c06\u91c7\u7528\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u8fdb\u884c\u5206\u7c7b\u3002 Labeling Grasp Hypotheses \u00b6 \u8bb8\u591a\u6293\u53d6\u70b9\u68c0\u6d4b\u7b97\u6cd5\u9700\u8981\u5927\u91cf\u4eba\u5de5\u6807\u8bb0\u597d\u6293\u53d6\u70b9\u7684\u6570\u636e\u96c6\uff0c\u8fd9\u4e2a\u5de5\u4f5c\u9700\u8981\u5f88\u5927\u7684\u4eba\u529b\u4e14\u4e0d\u8ba8\u597d\uff0c\u56e0\u4e3a\u4eba\u5f88\u96be\u786e\u5b9a\u5728\u4efb\u4e00\u4e2a\u573a\u666f\u4e0b\u5bf9\u673a\u5668\u4eba\u6765\u8bf4\u54ea\u4e9b\u70b9\u662f\u6700\u597d\u7684\u6293\u53d6\u70b9\u3002Instead\uff0c\u8bba\u6587\u4e2d\u7684\u7b97\u6cd5\u6839\u636e 4)\u5b9a\u4e492 \u53ef\u4ece\u8bad\u7ec3\u96c6\u56fe\u4e2d\u81ea\u52a8\u751f\u6210\u6807\u8bb0\u3002 \u5b9a\u4e493\uff1a\u5b9a\u4e49\u4e86\u9608\u503c\u6761\u4ef6 k\\in N k\\in N and \\theta\\in[0, pi/2] \\theta\\in[0, pi/2] ,\u5728\u6761\u4ef6\u5185\u7684hand hypotheses\u662fnear hypotheses \u8bba\u6587\u4e2d\u7684\u5b9a\u4e49\u7684\u7b26\u53f7\u592a\u96be\u61c2 Feature Representation \u00b6 \u4e3a\u4e86\u8bad\u7ec3SVM\u6a21\u578b\uff0c\u9700\u8981\u7528\u4e00\u4e2aFeature Descriptor\u6765\u63cf\u8ff0Hand\u7684\u7279\u5f81\uff0c\u8bba\u6587\u4e2d\u9009\u62e9\u4f7f\u7528HOG\u7279\u5f81\u63cf\u8ff0\u5b50\uff0c \u5177\u4f53\u7684\u6ca1\u770b\u61c2 Creating the training set \u00b6 \u6839\u636eHOG\u7279\u5f81\u751f\u6210\u8bad\u7ec3\u96c6\uff0c\u4e5f\u662f\u5206\u6210\u4e86\u597d\u51e0\u6b65\uff0c\u770b\u56fe 7\uff09Robot Experiment \u00b6 \u4f7f\u7528\u7684\u673a\u5668\u4eba\uff1aBaxter robot from Rethink Robotics \u624b\u722a\uff1aBaxter gripper\uff0c\u95ed\u5408\u65f6\u95f4\u8ddd3cm\uff0c\u5f20\u5f00\u65f6\u95f4\u8ddd7cm\uff0c\u4e5f\u5c31\u662f\u8bf4\u8be5\u624b\u722a\u53ea\u80fd\u6293\u53d6\u5927\u5c0f\u57283-7cm\u4e4b\u95f4\u7684\u7269\u4f53\u3002 Computer\uff1aintel i7 3.5GHz with 16GB\u5185\u5b58 \u6df1\u5ea6\u4f20\u611f\u5668\uff1aAsus Xtion Pro range sensors \u91c7\u68374000hand hypotheses\uff0c\u5b9e\u73b0\u5728\u7ebf\u68c0\u6d4b\u548c\u9009\u62e9\u6700\u7ec8\u6267\u884c\u7684hand\u7684\u8fc7\u7a0b\u9700\u89812.7s\uff1b\u8bad\u7ec3SVM\u6a21\u578b\u9700\u89815\u5206\u949f \u7b97\u6cd5\u91c7\u7528C++\u5199\u7684\uff0c\u53ea\u8981\u6709Baxter\u548c\u5408\u9002\u7684range sensor\u5c31\u53ef\u4ee5\u590d\u73b0\u8bba\u6587\u4e2d\u7684\u5185\u5bb9\uff0c \u8be6\u60c5\u53c2\u8003ROS\u529f\u80fd\u5305 Grasp Selection \u00b6 \u5f53\u7b97\u6cd5\u751f\u6210\u4e86\u51e0\u767e\u4e0a\u5343\u4e2aantipodal hand\uff0c\u6700\u540e\u9700\u8981\u9009\u51fa\u6700\u597d\u7684\u4e00\u4e2a\u8fdb\u884c\u6267\u884c\u6293\u53d6\u4efb\u52a1\uff0c\u4e00\u79cd\u65b9\u5f0f\u662f\u9009\u62e9\u6700\u611f\u5174\u8da3\u7684\u7269\u4f53\u7684hand\uff0c\u6216\u8005\u9009\u62e9\u6700\u597d\u6293\u53d6\u7684\u4e00\u4e2ahand\u3002 \u7b2c\u4e00\uff0c\u6839\u636edistance\u548corientation\u628aantipodal hand\u8fdb\u884c\u805a\u7c7b\u3002\u5728\u6bcf\u4e2a\u65b0\u7684group\u4e2d\u8ba1\u7b97\u7c7b\u7684\u5747\u503c\u548c\u65b9\u5411\u7684\u5747\u503c\u4f5c\u4e3a\u65b0\u751f\u6210\u7684hand \u7b2c\u4e8c\uff0c\u6839\u636e\u673a\u5668\u4eba\u6700\u5bb9\u6613\u7684\u59ff\u6001\uff0c\u4ece\u65b0\u751f\u6210\u7684hand\u4e2d\u9009\u62e9\u673a\u5668\u4eba\u89c9\u5f97\u6700\u8212\u9002\u7684\u6293\u53d6\u59ff\u6001\u6240\u5bf9\u5e94\u7684hand 1 2 (1)\u5bf9\u6bcf\u4e00\u4e2ahand\u7684\u4f4d\u7f6e\u5148\u8ba1\u7b97\u5bf9\u5e94\u7684\u673a\u5668\u4eba\u9006\u8fd0\u52a8\u5b66\uff0c\u53bb\u6389\u65e0\u89e3\u6240\u5bf9\u5e94\u7684hand. (2)\u5269\u4e0b\u7684hand\u6839\u636e3\u4e2a\u6807\u51c6\u518d\u7ee7\u7eed\u5206\u7b49\u7ea7\uff1ajoint limit\uff0chand joint limit, **\u6ca1\u770b\u61c2** \u5355\u4e2a\u5bf9\u50cf\u6293\u53d6\u5b9e\u9a8c \u00b6 \u5b9e\u9a8c\u5bf9\u6bd4\u4e86\u5728\u65e0SVM\u5206\u7c7b\u7684\u60c5\u51b5\u4e0b1\u53ea\u773c\u548c2\u4e24\u53ea\u773c\u7684trial\u6210\u529f\u7387\u4e0e\u5728\u6709SVM\u5206\u7c7b\u7684\u60c5\u51b5\u4e0b1\u53ea\u773c\u548c2\u53ea\u773ctrial\u6210\u529f\u7387\u3002 \u591a\u4e2a\u5bf9\u50cf\u6293\u53d6\u5b9e\u9a8c \u00b6 \u4f7f\u7528\u4e0e\u6293\u53d6\u5355\u4e2a\u5bf9\u50cf\u540c\u6837\u7684\u7b97\u6cd5\uff08\u6709SVM\u548c2\u53ea\u773c\uff09\uff0c\u5728\u6742\u4e71\u7684\u80cc\u666f\u4e0b\u53ef\u5b9e\u73b0\u5e73\u574785%\u7684\u6210\u529f\u7387\u3002 \u8df3\u8f6c\u5230Deep Learning for Detecting Robotic Grasps","title":"Using Geometry to Detect Grasp Poses in 3D Point Clouds"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/3/#using-geometry-to-detect-grasp-poses-in-3d-point-clouds","text":"2015 \u7f8e\u56fd\u4e1c\u5317\u5927\u5b66 \u8ba1\u7b97\u673a\u4fe1\u606f\u79d1\u5b66\u5b66\u9662 Boston\uff0cMassachusetts\uff0cUSA \u8be5\u5b9e\u9a8c\u5ba4 (Helping Hands Lab) \u53c8\u53d1\u8868\u4e86\u51e0\u7bc7\u6293\u53d6\u7684\u8bba\u6587\uff0c \u4f5c\u8005Andreas ten Pas\u7684\u4e2a\u4eba\u7f51\u7ad9","title":"Using Geometry to Detect Grasp Poses in 3D Point Clouds"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/3/#1","text":"\u8bba\u6587\u63d0\u51fa\u4e86\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u6742\u4e71\u573a\u666f\u4e2d\u68c0\u6d4b\u65b0\u7269\u4f53\u7684\u6293\u53d6\u4f4d\u59ff\uff0c\u7b97\u6cd5\u7684\u8f93\u5165\u662f\u7269\u4f53\u7684\u70b9\u4e91\u548c\u673a\u5668\u4eba\u7684\u51e0\u4f55\u53c2\u6570\uff0c\u7b97\u6cd5\u7684\u8f93\u51fa\u662f\u4e00\u7cfb\u5217\u7684\u53ef\u4ee5\u5b9e\u73b0\u6293\u53d6\u7684\u4f4d\u59ff\u3002 \u8d21\u732e\u70b9\uff1a \uff081\uff09\u5bf9\u4e00\u4e2a\u6293\u53d6\u4f4d\u59ff\u5b9a\u4e49\u4e86\u4e00\u7cfb\u5217\u7684\u5fc5\u8981\u7684\u51e0\u4f55\u9650\u5b9a\u6761\u4ef6 (geometric grasp conditions) \uff0c\u8fd9\u4e9b\u9650\u5b9a\u6761\u4ef6\u53ef\u7528\u4e8e\u751f\u6210\u4e00\u7cfb\u5217\u7684\u5019\u9009\u6293\u53d6\u4f4d\u59ff (grasp hypotheses) \uff0c\u8fd9\u4f7f\u6211\u4eec\u7684\u5173\u6ce8\u70b9\u96c6\u4e2d\u5728\u53ef\u751f\u6210\u6293\u53d6\u4f4d\u59ff\u7684\u533a\u57df\u3002 \uff082\uff09\u9610\u8ff0\u4e86\u5982\u4f55\u4f7f\u7528geometric grasp conditions\u7528\u4e8e\u751f\u6210\u7528\u4e8e\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u6807\u8bb0\u6570\u636e\u96c6\u3002 \uff083\uff09\u8bba\u6587\u4e2d\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u5355\u4e2a\u7269\u4f53\u573a\u666f\u4e0b\u53d6\u5f9788%\u7684\u5e73\u5747\u6210\u529f\u7387\uff0c\u5728\u6742\u4e71\u80cc\u666f\u4e0b\u53d6\u5f9773%\u7684\u5e73\u5747\u6210\u529f\u7387\u3002 3. \u8bba\u6587\u4ee3\u7801\u5df2\u7ecf\u505a\u6210\u4e86ROS\u529f\u80fd\u5305\uff0c\u94fe\u63a5\uff1a http://wiki.ros.org/agile_grasp","title":"1\uff09\u6458\u8981"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/3/#2introduction","text":"\u4f5c\u8005\u628a\u673a\u5668\u4eba\u6293\u53d6\u5206\u6210\u4e24\u6b65\uff0c\u4f20\u7edf\u5730\u5206\u6210perception\u548cplanning\u3002Perception\u662f\u4f30\u8ba1\u88ab\u6293\u53d6\u5bf9\u8c61\u7684\u4f4d\u7f6e\u548c\u59ff\u6001\uff0c\u4e4b\u540e\u624d\u662f\u89c4\u5212\u8def\u5f84\u548c\u63a7\u5236\u673a\u5668\u4eba\u5b9e\u73b0\u6293\u53d6\u3002 \u96be\u70b9\u5c31\u5728\u4e8e\u5982\u4f55\u4f30\u8ba1\u6293\u53d6\u5bf9\u8c61\u7684\u4f4d\u59ff\u3002 \u7814\u7a76\u8005\u5df2\u7ecf\u63d0\u51fa\u4e86\u591a\u79cd\u6293\u53d6\u70b9\u68c0\u6d4b\u65b9\u6cd5\u3002\u5176\u4e2d\u4e00\u7c7b\u662f\u4eceRGBD\u6570\u636e\u4e2d\u4f7f\u7528\u6ed1\u7a97\u6cd5\uff08sliding window\uff09\u68c0\u6d4b\u6293\u53d6\u533a\u57df\uff0c\u53e6\u4e00\u4e9b\u65b9\u6cd5\u91c7\u7528\u4eba\u5de5\u5b9a\u4e49\u7684\u6293\u53d6\u4f4d\u59ff\u63cf\u8ff0\uff08grasp prototypes\uff09 \u4ee5\u4e0a\u6240\u8bf4\u4e24\u79cd\u65b9\u6cd5\u6ca1\u6709\u5173\u6ce8grasp geometry\uff0c\u70b9\u4e91\u6570\u636e\u53ef\u4ee5\u5e2e\u52a9\u7814\u7a76grasp geometry\u3002\u672c\u8bba\u6587\u4e2d\u7b97\u6cd5\u901a\u8fc7\u9884\u6d4b\u5f53\u524d\u573a\u666f\u4e0b\u5b58\u5728\u6240\u9700\u4e14\u8db3\u591f\u7684\u51e0\u4f55\u6761\u4ef6\u4ece\u800c\u751f\u6210\u6293\u53d6\u4f4d\u59ff\u3002 \u7b97\u6cd5\u5206\u6210\u4e24\u6b65: \uff081\uff09\u751f\u6210\u5927\u91cf\u7684\u540e\u5019\u9009\u6293\u53d6\u4f4d\u59ff\uff08grasp hypothesis\uff09\u3002\u9996\u5148\u7528\u51e0\u4f55\u4fe1\u606f\u51cf\u5c11\u91c7\u6837\u533a\u57df\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u91c7\u6837\u65b9\u6cd5\u751f\u6210grasp hypotheses, \u540c\u65f6\u6ee1\u8db3\u673a\u5668\u624b\u4e0e\u6293\u53d6\u5bf9\u50cf\u4e4b\u95f4\u4e0d\u53d1\u751f\u78b0\u649e\u548c\u673a\u68b0\u624b\u6293\u5fc5\u987b\u8986\u76d6\u5728\u5bf9\u50cf\u7684\u8868\u9762\u3002\u7b2c\u4e8c\u6b65\u7b97\u6cd5\u4f7f\u7528\u51e0\u4f55\u4fe1\u606f\u81ea\u52a8\u5730\u6807\u8bb0\u8bad\u7ec3\u6570\u636e\u96c6\u3002 \uff082\uff09\u5bf9\u751f\u6210\u7684\u5019\u9009\u6293\u53d6\u4f4d\u59ff\u8fdb\u884c\u5206\u7c7b \u5b9e\u9a8c\u663e\u793a\u8bba\u6587\u4e2d\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u4e0d\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u60c5\u51b5\u4e0b\u6293\u53d6\u65b0\u5bf9\u50cf\u53ef\u4ee5\u83b7\u5f9773%\u7684\u6210\u529f\u7387\u3002\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u4e4b\u540e\u6210\u529f\u7387\u4e0a\u5347\u523088%\u3002 \u4e14\u8bba\u6587\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u975e\u5e38\u6742\u4e71\u7684\u573a\u666f\u4e0b\u4ecd\u53ef\u53d6\u5f9773%\u7684\u5e73\u5747\u6210\u529f\u7387\u3002","title":"2\uff09Introduction"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/3/#3related-work","text":"\u6293\u53d6\u70b9\u8bc6\u522b\u65b9\u6cd5\uff0c\u6700\u5f00\u59cb\u5728RGBD\u56fe\u50cf\u4e2d\u4f7f\u7528sliding window\u8bc6\u522b\u6293\u53d6\u533a\u57df\uff0c\u4e4b\u540e\u7814\u7a76\u8005\u5728\u8fd9\u57fa\u7840\u4e0a\u6269\u5c55\u8be5\u65b9\u6cd5\u5b9e\u73b0\u6293\u53d6\uff0c\u5e76\u53d6\u5f97\u4e00\u5b9a\u7684\u6293\u53d6\u6210\u529f\u7387\u3002\u522b\u7684\u4e00\u4e9b\u65b9\u6cd5\u662f\u57fa\u4e8e\u70b9\u4e91\u6570\u636e\uff08point cloud\uff09\u6216\u8005RGB\u6570\u636e\uff0c \u4e0d\u60f3\u4ed4\u7ec6\u770b\u4e86","title":"3\uff09Related Work"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/3/#4approach","text":"\u5b9a\u4e491\uff1aAntipodoal: \u5b9a\u4e492\uff1aAntipodoal Hand:\u4e8c\u5e73\u884c\u624b\u6307\u7684\u59ff\u6001\uff0c\u59ff\u6001\u7684\u63a5\u89e6\u70b9\u4f7f\u4e8c\u6307\u95ed\u5408\u65f6\u529b\u7684\u65b9\u5411\u6cbf\u7740\u4e24\u63a5\u89e6\u70b9\u7684\u8fde\u7ebf\u4e0a \u7b97\u6cd5\u7684\u53ef\u8868\u793a\u4e3a\uff1a","title":"4\uff09Approach"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/3/#5sampling-hands-hand-hypotheses","text":"","title":"5\uff09\u91c7\u6837\u6293\u53d6\u59ff\u6001Sampling Hands \uff08\u751f\u6210hand hypotheses\uff09"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/3/#geometry-of-the-hand-and-the-object-surface","text":"\u673a\u68b0\u624b\u722a\u7684\u53c2\u6570\u901a\u8fc7\u53c2\u6570\u5411\u91cf \\theta = (\\theta_l, \\theta_w, \\theta_d, \\theta_t) \\theta = (\\theta_l, \\theta_w, \\theta_d, \\theta_t) \u6765\u63cf\u8ff0\uff0c \\theta_t \\theta_t \u8868\u793a\u624b\u6307\u7684\u539a\u5ea6\uff0c\u5982\u4f55\u4e0b\u56fe\u6240\u793a\uff1a \u8bba\u6587\u4e2d\u5b9a\u4e49\u597d\u591a\u516c\u5f0f\u770b\u4e0d\u61c2\uff0c\u8fd8\u5f15\u7528\u4e86\u4e00\u4e9b\u65b9\u6cd5\u8fdb\u884c\u62df\u5408","title":"Geometry of the Hand and the Object Surface"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/3/#hand-sample-set","text":"\u751f\u6210\u4e00\u4e2a\u6570\u636e\u96c6 H H \uff0c\u8be5\u6570\u636e\u96c6\u5305\u542b\u8bb8\u591aantipodal hands (h\\in H) (h\\in H) , \u9996\u5148\u8981\u5b9a\u4e493\u4e2a\u9650\u5236\u6761\u4ef6 \u673a\u68b0\u624b\u722a\u4e0e\u70b9\u4e91\u4e4b\u95f4\u6ca1\u6709\u78b0\u649e \u624b\u722a\u95ed\u5408\u5e73\u9762(hand closing plane)\u5305\u542bp: p\\in C(h) p\\in C(h) \u624b\u722a\u7684\u95ed\u5408\u5e73\u9762\u548c\u7269\u4f53\u70b9\u4e91\u7684\u5207\u5e73\u9762(cutting plane)\u5e73\u884c \u7b97\u6cd5\u63cf\u8ff0\uff1a\u9700\u8981\u7528\u7684\u65f6\u5019\u518d\u8fd4\u56de\u6765\u4ed4\u7ec6\u770b","title":"Hand Sample Set"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/3/#6classifying-hand-hypotheses","text":"\u5728\u6b65\u9aa45\uff09\u4e2d\u751f\u6210\u4e86hand hypotheses\uff0c\u5728\u8fd9\u4e00\u6b65\u6839\u636e\u5176\u662f\u5426\u4e3aantipodal hand\u5bf9\u5b83\u8fdb\u884c\u5206\u7c7b\u3002\u6700\u7b80\u5355\u7684\u65b9\u6cd5\u662f\u53c2\u8003\u5bf9\u50cf\u8868\u9762\u7684\u70b9\u4e91\u6570\u636e\u6765\u68c0\u6d4bhand hypotheses\u662f\u5426\u6ee1\u8db3 \u59ff\u6001\u7684\u63a5\u89e6\u70b9\u4f7f\u4e8c\u6307\u95ed\u5408\u65f6\u529b\u7684\u65b9\u5411\u6cbf\u7740\u4e24\u63a5\u89e6\u70b9\u7684\u8fde\u7ebf\u4e0a \uff0c \u4f46\u662f\u5f88\u591a\u771f\u5b9e\u7684\u70b9\u4e91\u6570\u636e\u53ea\u80fd\u770b\u5230\u5bf9\u50cf\u7684\u90e8\u5206 \uff0c\u6309\u71674\uff09\u5b9a\u4e492\u7684\u8981\u6c42\u6765\u68c0\u6d4bhand hypotheses\uff0c\u5219\u5f88\u5927\u90e8\u5206\u4e0d\u6ee1\u8db3\u8981\u6c42\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u8bba\u6587\u4e2d\u5c06\u91c7\u7528\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u8fdb\u884c\u5206\u7c7b\u3002","title":"6\uff09Classifying Hand Hypotheses"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/3/#labeling-grasp-hypotheses","text":"\u8bb8\u591a\u6293\u53d6\u70b9\u68c0\u6d4b\u7b97\u6cd5\u9700\u8981\u5927\u91cf\u4eba\u5de5\u6807\u8bb0\u597d\u6293\u53d6\u70b9\u7684\u6570\u636e\u96c6\uff0c\u8fd9\u4e2a\u5de5\u4f5c\u9700\u8981\u5f88\u5927\u7684\u4eba\u529b\u4e14\u4e0d\u8ba8\u597d\uff0c\u56e0\u4e3a\u4eba\u5f88\u96be\u786e\u5b9a\u5728\u4efb\u4e00\u4e2a\u573a\u666f\u4e0b\u5bf9\u673a\u5668\u4eba\u6765\u8bf4\u54ea\u4e9b\u70b9\u662f\u6700\u597d\u7684\u6293\u53d6\u70b9\u3002Instead\uff0c\u8bba\u6587\u4e2d\u7684\u7b97\u6cd5\u6839\u636e 4)\u5b9a\u4e492 \u53ef\u4ece\u8bad\u7ec3\u96c6\u56fe\u4e2d\u81ea\u52a8\u751f\u6210\u6807\u8bb0\u3002 \u5b9a\u4e493\uff1a\u5b9a\u4e49\u4e86\u9608\u503c\u6761\u4ef6 k\\in N k\\in N and \\theta\\in[0, pi/2] \\theta\\in[0, pi/2] ,\u5728\u6761\u4ef6\u5185\u7684hand hypotheses\u662fnear hypotheses \u8bba\u6587\u4e2d\u7684\u5b9a\u4e49\u7684\u7b26\u53f7\u592a\u96be\u61c2","title":"Labeling Grasp Hypotheses"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/3/#feature-representation","text":"\u4e3a\u4e86\u8bad\u7ec3SVM\u6a21\u578b\uff0c\u9700\u8981\u7528\u4e00\u4e2aFeature Descriptor\u6765\u63cf\u8ff0Hand\u7684\u7279\u5f81\uff0c\u8bba\u6587\u4e2d\u9009\u62e9\u4f7f\u7528HOG\u7279\u5f81\u63cf\u8ff0\u5b50\uff0c \u5177\u4f53\u7684\u6ca1\u770b\u61c2","title":"Feature Representation"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/3/#creating-the-training-set","text":"\u6839\u636eHOG\u7279\u5f81\u751f\u6210\u8bad\u7ec3\u96c6\uff0c\u4e5f\u662f\u5206\u6210\u4e86\u597d\u51e0\u6b65\uff0c\u770b\u56fe","title":"Creating the training set"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/3/#7robot-experiment","text":"\u4f7f\u7528\u7684\u673a\u5668\u4eba\uff1aBaxter robot from Rethink Robotics \u624b\u722a\uff1aBaxter gripper\uff0c\u95ed\u5408\u65f6\u95f4\u8ddd3cm\uff0c\u5f20\u5f00\u65f6\u95f4\u8ddd7cm\uff0c\u4e5f\u5c31\u662f\u8bf4\u8be5\u624b\u722a\u53ea\u80fd\u6293\u53d6\u5927\u5c0f\u57283-7cm\u4e4b\u95f4\u7684\u7269\u4f53\u3002 Computer\uff1aintel i7 3.5GHz with 16GB\u5185\u5b58 \u6df1\u5ea6\u4f20\u611f\u5668\uff1aAsus Xtion Pro range sensors \u91c7\u68374000hand hypotheses\uff0c\u5b9e\u73b0\u5728\u7ebf\u68c0\u6d4b\u548c\u9009\u62e9\u6700\u7ec8\u6267\u884c\u7684hand\u7684\u8fc7\u7a0b\u9700\u89812.7s\uff1b\u8bad\u7ec3SVM\u6a21\u578b\u9700\u89815\u5206\u949f \u7b97\u6cd5\u91c7\u7528C++\u5199\u7684\uff0c\u53ea\u8981\u6709Baxter\u548c\u5408\u9002\u7684range sensor\u5c31\u53ef\u4ee5\u590d\u73b0\u8bba\u6587\u4e2d\u7684\u5185\u5bb9\uff0c \u8be6\u60c5\u53c2\u8003ROS\u529f\u80fd\u5305","title":"7\uff09Robot Experiment"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/3/#grasp-selection","text":"\u5f53\u7b97\u6cd5\u751f\u6210\u4e86\u51e0\u767e\u4e0a\u5343\u4e2aantipodal hand\uff0c\u6700\u540e\u9700\u8981\u9009\u51fa\u6700\u597d\u7684\u4e00\u4e2a\u8fdb\u884c\u6267\u884c\u6293\u53d6\u4efb\u52a1\uff0c\u4e00\u79cd\u65b9\u5f0f\u662f\u9009\u62e9\u6700\u611f\u5174\u8da3\u7684\u7269\u4f53\u7684hand\uff0c\u6216\u8005\u9009\u62e9\u6700\u597d\u6293\u53d6\u7684\u4e00\u4e2ahand\u3002 \u7b2c\u4e00\uff0c\u6839\u636edistance\u548corientation\u628aantipodal hand\u8fdb\u884c\u805a\u7c7b\u3002\u5728\u6bcf\u4e2a\u65b0\u7684group\u4e2d\u8ba1\u7b97\u7c7b\u7684\u5747\u503c\u548c\u65b9\u5411\u7684\u5747\u503c\u4f5c\u4e3a\u65b0\u751f\u6210\u7684hand \u7b2c\u4e8c\uff0c\u6839\u636e\u673a\u5668\u4eba\u6700\u5bb9\u6613\u7684\u59ff\u6001\uff0c\u4ece\u65b0\u751f\u6210\u7684hand\u4e2d\u9009\u62e9\u673a\u5668\u4eba\u89c9\u5f97\u6700\u8212\u9002\u7684\u6293\u53d6\u59ff\u6001\u6240\u5bf9\u5e94\u7684hand 1 2 (1)\u5bf9\u6bcf\u4e00\u4e2ahand\u7684\u4f4d\u7f6e\u5148\u8ba1\u7b97\u5bf9\u5e94\u7684\u673a\u5668\u4eba\u9006\u8fd0\u52a8\u5b66\uff0c\u53bb\u6389\u65e0\u89e3\u6240\u5bf9\u5e94\u7684hand. (2)\u5269\u4e0b\u7684hand\u6839\u636e3\u4e2a\u6807\u51c6\u518d\u7ee7\u7eed\u5206\u7b49\u7ea7\uff1ajoint limit\uff0chand joint limit, **\u6ca1\u770b\u61c2**","title":"Grasp Selection"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/3/#_1","text":"\u5b9e\u9a8c\u5bf9\u6bd4\u4e86\u5728\u65e0SVM\u5206\u7c7b\u7684\u60c5\u51b5\u4e0b1\u53ea\u773c\u548c2\u4e24\u53ea\u773c\u7684trial\u6210\u529f\u7387\u4e0e\u5728\u6709SVM\u5206\u7c7b\u7684\u60c5\u51b5\u4e0b1\u53ea\u773c\u548c2\u53ea\u773ctrial\u6210\u529f\u7387\u3002","title":"\u5355\u4e2a\u5bf9\u50cf\u6293\u53d6\u5b9e\u9a8c"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/3/#_2","text":"\u4f7f\u7528\u4e0e\u6293\u53d6\u5355\u4e2a\u5bf9\u50cf\u540c\u6837\u7684\u7b97\u6cd5\uff08\u6709SVM\u548c2\u53ea\u773c\uff09\uff0c\u5728\u6742\u4e71\u7684\u80cc\u666f\u4e0b\u53ef\u5b9e\u73b0\u5e73\u574785%\u7684\u6210\u529f\u7387\u3002 \u8df3\u8f6c\u5230Deep Learning for Detecting Robotic Grasps","title":"\u591a\u4e2a\u5bf9\u50cf\u6293\u53d6\u5b9e\u9a8c"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/SegICP/","text":"SegICP: Integrated Deep Semantic Segmentation and Pose Estimation \u00b6 For full documentation visit mkdocs.org . Commands \u00b6 mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message. Project layout \u00b6 1 2 3 4 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"SegICP-Integrated Deep Semantic Segmentation and Pose Estimation"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/SegICP/#segicp-integrated-deep-semantic-segmentation-and-pose-estimation","text":"For full documentation visit mkdocs.org .","title":"SegICP: Integrated Deep Semantic Segmentation and Pose Estimation"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/SegICP/#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message.","title":"Commands"},{"location":"PaperNote/\u6df1\u5ea6\u5b66\u4e60\u6293\u53d6/SegICP/#project-layout","text":"1 2 3 4 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"Projects/\u603b\u8ff0/","text":"\u9879\u76ee\u603b\u8ff0 \u00b6 \u8be5\u9875\u4e0b\u4e3b\u8981\u8bb0\u5f55Yang\u7ecf\u5386\u8fc7\u7684\u9879\u76ee\u7b14\u8bb0\uff0c\u5305\u542b\u9879\u76ee\u8bbe\u5907\u4ecb\u7ecd\uff0c\u7cfb\u7edf\u642d\u5efa\u8fc7\u7a0b\u548c\u5b9e\u9a8c\u7ed3\u679c\u7b49","title":"\u9879\u76ee\u603b\u8ff0"},{"location":"Projects/\u603b\u8ff0/#_1","text":"\u8be5\u9875\u4e0b\u4e3b\u8981\u8bb0\u5f55Yang\u7ecf\u5386\u8fc7\u7684\u9879\u76ee\u7b14\u8bb0\uff0c\u5305\u542b\u9879\u76ee\u8bbe\u5907\u4ecb\u7ecd\uff0c\u7cfb\u7edf\u642d\u5efa\u8fc7\u7a0b\u548c\u5b9e\u9a8c\u7ed3\u679c\u7b49","title":"\u9879\u76ee\u603b\u8ff0"},{"location":"Projects/\u6fc0\u5149\u626b\u63cf3D\u91cd\u5efa\u53ca\u6253\u78e8/3D\u91cd\u5efa/","text":"\u6fc0\u5149\u626b\u63cf3D\u91cd\u5efa\u53ca\u6253\u78e8 \u00b6 1.\u57fa\u4e8eLMI\u6fc0\u5149\u5668\u76843\u7ef4\u91cd\u5efa \u00b6 1\uff09LMI\u6fc0\u5149\u626b\u63cf\u4eea\u7b80\u4ecb \u00b6","title":"LMI\u6fc0\u5149\u626b\u63cf3D\u91cd\u5efa\u53ca\u6253\u78e8"},{"location":"Projects/\u6fc0\u5149\u626b\u63cf3D\u91cd\u5efa\u53ca\u6253\u78e8/3D\u91cd\u5efa/#3d","text":"","title":"\u6fc0\u5149\u626b\u63cf3D\u91cd\u5efa\u53ca\u6253\u78e8"},{"location":"Projects/\u6fc0\u5149\u626b\u63cf3D\u91cd\u5efa\u53ca\u6253\u78e8/3D\u91cd\u5efa/#1lmi3","text":"","title":"1.\u57fa\u4e8eLMI\u6fc0\u5149\u5668\u76843\u7ef4\u91cd\u5efa"},{"location":"Projects/\u6fc0\u5149\u626b\u63cf3D\u91cd\u5efa\u53ca\u6253\u78e8/3D\u91cd\u5efa/#1lmi","text":"","title":"1\uff09LMI\u6fc0\u5149\u626b\u63cf\u4eea\u7b80\u4ecb"}]}